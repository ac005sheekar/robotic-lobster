<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Projects - Sheekar Banerjee</title>
  
  <meta name="author" content="Sheekar Banerjee">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css">
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.slim.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script>
  <link rel="icon" type="image/png" href="sheekar2.jpg">
</head>

<body>
  <nav class="navbar navbar-expand-sm bg-dark navbar-dark">
    <!-- Brand/logo -->
    <a class="navbar-brand" href="index.html">Home</a>
    
    <!-- Links -->
    <ul class="navbar-nav">
      <li class="nav-item">
        <a class="nav-link" href="research.html">Research</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="projects.html">Projects</a>
      </li>
      <!-- <li class="nav-item">
        <a class="nav-link" href="teach.html">Teaching</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="Contest.html">Contests & Hackathons</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="workshops.html">Workshops</a>
      </li> -->
    </ul>
  </nav><br>
  
      <table style="width:75%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading><strong>Projects</strong></heading>
          </td>
        </tr>
      </tbody></table>

      <!-- Papers list -->
      <table style="width:75%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="pose.JPG" width="160" height="100">
        </td>
        <td width="75%" valign="middle">
          <!-- <a href="video link to be added..."> -->
            <strong><papertitle>Multiple Person Pose Estimation for Robot Vision and Streaming with Socket Programming to 
              TCP Server</papertitle> [2023]</strong>
          </a>
          <br>
            
          <p> This is a very small part of a gigantic confidential South Korean project where 
            multiple persons' pose estimation and keypoint tracking have been done. The data values of the landmarks
            have been streamed to the TCP Server through Socket Programming with Python. YOLO version 3 has been used for 
            pose estimation and tracking. Further improvement has been going on which cannot be shared due to 
            strict project confidentiality.
          </p>
          [<a href="https://youtu.be/PdYfGs-6CJM">Single Person Demo</a>] / 
          [<a href="https://youtu.be/sA4SLYT__oc">Multiple Person Demo</a>] / 
          [<a href="https://github.com/ac005sheekar/Multipose-yolov3-tcp">code</a>]
        </td>
      </tr> </tbody></table>

<br><br>


      <table style="width:75%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="recog2.JPG" width="160" height="100">
        </td>
        <td width="75%" valign="middle">
          <!-- <a href="video link to be added..."> -->
            <strong><papertitle>Cutting Edge Object Recognition for Robot Vision and Data feeding to the Unreal Engine with Socket Programming</papertitle> [2023]</strong>
              
          </a>
          <br>
            
          <p> This is a code fragment of another large confidential South Korean project where 
            multiple object recognition has been done. The object data values 
            have been streamed to the TCP Server alinged with Unreal Engine 5 environment through Socket Programming 
            with Python. Here, YOLO version 7 has been used for 
            continuous object recognition and tracking. Further improvement has been going on which cannot be shared due to 
            strict project confidentiality.
          </p>
          [<a href="https://youtu.be/jUR3j4k-UaM">Demo 1</a>] / 
          [<a href="https://youtu.be/Egah9hEqD1I">Demo 2</a>] / 
          [<a href="https://github.com/ac005sheekar/YOLO-V7-TCP-Server-Socket-Programming">code</a>]
        </td>
      </tr> </tbody></table>



<br><br>
      <table style="width:75%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="facedis.PNG" width="160" height="100">
        </td>
        <td width="75%" valign="middle">
          <!-- <a href="video link to be added..."> -->
            <strong><papertitle>Face Distance Measurement for AI Digital Human's Greetings Feature </papertitle> [2023]</strong>
          </a>
          <br>
            
          <p> This is a code fragment of a magnanimous confidential South Korean project where 
            greetings feature has been done with face distance measurement with OpenCV. The distance data values 
            have been streamed to the Flask and TCP Server alinged with Unreal Engine 5 environment through Socket Programming 
            with Python. Further improvement has been going on which cannot be shared due to 
            strict project confidentiality.
          </p>
          [<a href="https://youtu.be/68SmZxU9GW4">Demo 1</a>] / 
          [<a href="https://youtu.be/5BAI8DyfecM">Demo 2</a>] / 
          [<a href="https://youtu.be/gdhrFTPIeLo">Demo 3</a>] / 
          [<a href="https://github.com/ac005sheekar/Face-Distance-OpenCV-TCP-Server-Socket-Programming">code</a>]
        </td>
      </tr> </tbody></table>


<br><br>

        


        <table style="width:75%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="alz.PNG" width="160" height="100">
          </td>
          <td width="75%" valign="middle">
            <!-- <a href="https://www.youtube.com/watch?v=ocCYdEAt0do"> -->
              <strong><papertitle>Alzheimer's Disease Stage Detection with Deep Learning in Android App</papertitle> [2022]</strong>
            </a>
            <br>
              
            <p> This is an Android mobile application prototype where user can upload a Tomographic Brain X-ray image 
              into the system and get an AI based prediction out of it. The prediction mainly relates to the 
              stage detection of Alzheimer's disease such as: Dimented, Mild Dimented, Very Mild Dimented and 
              Non Demented. Here, I implemented the deep learning model with Tensorflow framework, converted the artifact 
              into Tf-Lite and served it to the Android platform.
            </p>
            [<a href="https://www.youtube.com/watch?v=ocCYdEAt0do">Demo</a>] /
            [<a href="https://github.com/ac005sheekar/Alzheimer-s-Disease-Stage-Detection-with-Deep-Learning-in-Android-App">code</a>]
          </td>
        </tr> </tbody></table>

<br><br>


        <table style="width:75%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="vent.jpg" width="160" height="100">
          </td>
          <td width="75%" valign="middle">
            <!-- <a href="https://www.facebook.com/watch/?v=2652088795047266"> -->
              <strong><papertitle>SENSO CODER Ventilator Simulation with Robotic Arm Approach for COVID-19 Patients</papertitle> [2020]</strong>
            </a>
            <br>
              Supervised by: Prof. Rashedul Islam <br>
            <p> This is a design based simulation project which represents a research proposal of a cost-efficient
              sensor based ventilation system with Robotic Arm Approach, for COVID-19 patients in the
              rural area. On the verge of a massive first wave of COVID-19 outbreak at March'20, studying as a final
              year undergraduate student, I led this simulation project collaborating with three mechanical
              engineering students at my university.
              Demonstrated the features of Leakage Free Oxygen Source, Ventilation Bag attached with
              Robotic Arm with Transverse Angle, Programmed Stepper Motor for real time Frequency Con-
              trol and Precise Air Diffusion Rate and Respiratory Sensor for reading the Breathing Rate of
              the patient.
              Got acclamation from the Professors at my University due to the realistic feasibility of the
              design.
            </p>
            [<a href="https://www.facebook.com/watch/?v=2652088795047266">Demo</a>]
          </td>
        </tr> </tbody></table>

<br><br>

        <table style="width:75%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="sim.jpg" width="160" height="100">
          </td>
          <td width="75%" valign="middle">
            <!-- <a href="https://drive.google.com/file/d/1QluBgO41rm-hCyALDVJFozxfRJXWb1Kx/view?usp=sharing"> -->
              <strong><papertitle>The Smart Injector: A Robotic Approach of
                Automated Multiple Injection System for
                Critical Patients using Real Time Clock Feature</papertitle> [2019]</strong>
            </a>
            <br>
              
            <p> In the rural world of medical services, we
              generally notice a lot of havoc which generally happens
              in the hospitals, clinics and related other medical
              centers. The conditions of Intensive Care Units (ICU) of
              the rural areas are quite intolerable because of the lack
              of qualified nurses. Doctors generally prescribe multiple
              injections for a single patient for each day. Nurses are
              responsible for the injection process but unfortunately
              they fail to perform the injection process very often in
              proper prescribed time in proper amount. This
              malpractice of treatment quite often results in the
              terrible sufferings of the ICU patients and sometimes a
              few patients even die. This study aims to minimize the
              hazard at the highest accuracy level possible. The
              research relates to the functionality of Real Time Clock
              (RTC) which provides the activation of automated time
              system and triggers the microcontroller's machinery to
              act according to the time. According to the doctor's
              prescribed time, injection's medicine will be flowing
              inside the pipelines and will be injected to the body of
              the patient through a cannula. In this study, Arduino
              microcontroller, RTC DS3231 time module, HX 711
              weight sensors, relay modules, hydraulic pump motors,
              wifi shield, resistors, MOSFET and breadboard have
              been used. Following the prescribed time of doctor, the
              RTC module programs the time for the activation of the
              microcontroller. The microcontroller activates the
              hydraulic pump motors following the programmed
              times. The pump motors then create a vacuum
              environment inside the pipeline and pass the medicine
              fluid for injection inside the patient's body through the
              multiple channel-single cannula. This is consisted of
              three units: electrical circuitry unit, mechanical unit
              and timer program with reprogram process unit. The
              research were carried out through the tests of each and
              every units to verify that they were working precisely
              and were manifesting the expected outputs.
            </p>
            [<a href="https://drive.google.com/file/d/1QluBgO41rm-hCyALDVJFozxfRJXWb1Kx/view?usp=sharing">Paper</a>]
          </td>
        </tr> </tbody></table>





<br><br>

      
        


        
      </td>
    </tr>
  </table>
</body>

</html>
